{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Playground\n",
    "\n",
    "**Watch** a [short tutorial video](https://greatexpectations.io/videos/getting_started/integrate_expectations) or **read** [the written tutorial](https://docs.greatexpectations.io/en/latest/tutorials/validate_data.html?utm_source=notebook&utm_medium=validate_data)\n",
    "\n",
    "#### This notebook assumes that you created at least one expectation suite in your project.\n",
    "#### Here you will learn how to validate data loaded into a Pandas DataFrame against an expectation suite.\n",
    "\n",
    "\n",
    "We'd love it if you **reach out for help on** the [**Great Expectations Slack Channel**](https://greatexpectations.io/slack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lais_carvalho/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-10T16:31:00+0100 - INFO - Great Expectations logging enabled at 20 level by JupyterUX module.\n",
      "2020-09-10 16:31:00,423 - great_expectations - INFO - Great Expectations logging enabled at 20 level by JupyterUX module.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import great_expectations as ge\n",
    "import great_expectations.jupyter_ux\n",
    "from great_expectations.datasource.types import BatchKwargs\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get a DataContext\n",
    "This represents your **project** that you just created using `great_expectations init`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-10 16:31:03,801 - py.warnings - WARNING - /Users/lais_carvalho/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "\n",
      "2020-09-10 16:31:03,893 - py.warnings - WARNING - /Users/lais_carvalho/anaconda3/lib/python3.7/site-packages/jsonschema/validators.py:928: DeprecationWarning: The metaschema specified by $schema was not found. Using the latest draft to validate, but this will raise an error in the future.\n",
      "  cls = validator_for(schema)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "context = ge.data_context.DataContext()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Choose an Expectation Suite\n",
    "\n",
    "List expectation suites that you created in your project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pandas_penguins_data', 'spark_penguins_data']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context.list_expectation_suite_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "expectation_suite_name =  'pandas_penguins_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load a batch of data you want to validate\n",
    "\n",
    "To learn more about `get_batch`, see [this tutorial](https://docs.greatexpectations.io/en/latest/tutorials/validate_data.html?utm_source=notebook&utm_medium=validate_data#load-a-batch-of-data-to-validate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pandas_penguins']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list datasources of the type PandasDatasource in your project\n",
    "[datasource['name'] for datasource in context.list_datasources() if datasource['class_name'] == 'PandasDatasource']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasource_name = 'pandas_penguins'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "BatchKwargsError",
     "evalue": "Invalid batch_kwargs: path, s3, or df is required for a PandasDatasource",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBatchKwargsError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-8cfe4d3df9f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpectation_suite_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/great_expectations/data_context/data_context.py\u001b[0m in \u001b[0;36mget_batch\u001b[0;34m(self, batch_kwargs, expectation_suite_name, data_asset_type, batch_parameters)\u001b[0m\n\u001b[1;32m    935\u001b[0m         \u001b[0mdatasource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_datasource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"datasource\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m         batch = datasource.get_batch(\n\u001b[0;32m--> 937\u001b[0;31m             \u001b[0mbatch_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    938\u001b[0m         )\n\u001b[1;32m    939\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata_asset_type\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/great_expectations/datasource/pandas_datasource.py\u001b[0m in \u001b[0;36mget_batch\u001b[0;34m(self, batch_kwargs, batch_parameters)\u001b[0m\n\u001b[1;32m    235\u001b[0m             raise BatchKwargsError(\n\u001b[1;32m    236\u001b[0m                 \u001b[0;34m\"Invalid batch_kwargs: path, s3, or df is required for a PandasDatasource\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m                 \u001b[0mbatch_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m             )\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBatchKwargsError\u001b[0m: Invalid batch_kwargs: path, s3, or df is required for a PandasDatasource"
     ]
    }
   ],
   "source": [
    "# If you would like to validate a file on a filesystem:\n",
    "batch_kwargs = {'path': \"../data/01_raw\", 'datasource': datasource_name}\n",
    "\n",
    "# If you already loaded the data into a Pandas Data Frame:\n",
    "batch_kwargs = {'dataset': \"../data/01_raw\", 'datasource': datasource_name}\n",
    "\n",
    "\n",
    "batch = context.get_batch(batch_kwargs, expectation_suite_name)\n",
    "batch.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Validate the batch with Validation Operators\n",
    "\n",
    "`Validation Operators` provide a convenient way to bundle the validation of\n",
    "multiple expectation suites and the actions that should be taken after validation.\n",
    "\n",
    "When deploying Great Expectations in a **real data pipeline, you will typically discover these needs**:\n",
    "\n",
    "* validating a group of batches that are logically related\n",
    "* validating a batch against several expectation suites such as using a tiered pattern like `warning` and `failure`\n",
    "* doing something with the validation results (e.g., saving them for a later review, sending notifications in case of failures, etc.).\n",
    "\n",
    "[Read more about Validation Operators in the tutorial](https://docs.greatexpectations.io/en/latest/tutorials/validate_data.html?utm_source=notebook&utm_medium=validate_data#save-validation-results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-f4ba879f58ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m results = context.run_validation_operator(\n\u001b[1;32m     17\u001b[0m     \u001b[0;34m\"action_list_operator\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0massets_to_validate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     run_id=run_id)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'batch' is not defined"
     ]
    }
   ],
   "source": [
    "# This is an example of invoking a validation operator that is configured by default in the great_expectations.yml file\n",
    "\n",
    "\"\"\"\n",
    "Create a run_id. The run_id must be of type RunIdentifier, with optional run_name and run_time instantiation\n",
    "arguments (or a dictionary with these keys). The run_name can be any string (this could come from your pipeline\n",
    "runner, e.g. Airflow run id). The run_time can be either a dateutil parsable string or a datetime object.\n",
    "Note - any provided datetime will be assumed to be a UTC time. If no instantiation arguments are given, run_name will\n",
    "be None and run_time will default to the current UTC datetime.\n",
    "\"\"\"\n",
    "\n",
    "run_id = {\n",
    "  \"run_name\": \"some_string_that_uniquely_identifies_this_run\",  # insert your own run_name here\n",
    "  \"run_time\": datetime.datetime.now(datetime.timezone.utc)\n",
    "}\n",
    "\n",
    "results = context.run_validation_operator(\n",
    "    \"action_list_operator\",\n",
    "    assets_to_validate=[batch],\n",
    "    run_id=run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. View the Validation Results in Data Docs\n",
    "\n",
    "Let's now build and look at your Data Docs. These will now include an **data quality report** built from the `ValidationResults` you just created that helps you communicate about your data with both machines and humans.\n",
    "\n",
    "[Read more about Data Docs in the tutorial](https://docs.greatexpectations.io/en/latest/tutorials/validate_data.html?utm_source=notebook&utm_medium=validate_data#view-the-validation-results-in-data-docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context.open_data_docs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations! You ran Validations!\n",
    "\n",
    "## Next steps:\n",
    "\n",
    "### 1. Read about the typical workflow with Great Expectations:\n",
    "\n",
    "[typical workflow](https://docs.greatexpectations.io/en/latest/getting_started/typical_workflow.html?utm_source=notebook&utm_medium=validate_data#view-the-validation-results-in-data-docs)\n",
    "\n",
    "### 2. Explore the documentation & community\n",
    "\n",
    "You are now among the elite data professionals who know how to build robust descriptions of your data and protections for pipelines and machine learning models. Join the [**Great Expectations Slack Channel**](https://greatexpectations.io/slack) to see how others are wielding these superpowers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "palmer_penguins",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
